{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:48:09.583962: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-03 14:48:09.614488: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-03 14:48:09.615363: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-03 14:48:10.295299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.12.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abduraxim/Documents/tensorflow_imagenet/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras import Model\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:48:18.320288: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_INVALID_DEVICE: invalid device ordinal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:48:18.320395: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: myarch\n",
      "2023-04-03 14:48:18.320402: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: myarch\n",
      "2023-04-03 14:48:18.320488: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 530.41.3\n",
      "2023-04-03 14:48:18.320507: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 530.41.3\n",
      "2023-04-03 14:48:18.320512: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 530.41.3\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tfds.load(\"siscore/rotation\", split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = tfds.builder('siscore/rotation')\n",
    "# img = img.as_dataset()\n",
    "dataset = tfds.load(\"siscore/rotation\", split = \"test\")\n",
    "batch_size = 32\n",
    "dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for example in tfds.as_numpy(img['test']):\n",
    "#       image.append(example['image'])\n",
    "#       label.append(example['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = np.array(image)/255.0\n",
    "# labels = np.array(label)/255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds = tf.data.Dataset.from_tensor_slices((images, labels)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#   try:\n",
    "#     # Currently, memory growth needs to be the same across GPUs\n",
    "#     for gpu in gpus:\n",
    "#       tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#     # Restrict TensorFlow to only use the first GPU\n",
    "#     tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "#   except RuntimeError as e:\n",
    "#     # Visible devices must be set before GPUs have been initialized\n",
    "#     print(e)\n",
    "\n",
    "# # Load the \"test\" split of the \"siscore/rotation\" dataset\n",
    "# dataset = tfds.load(\"siscore/rotation\", split=\"test\")\n",
    "\n",
    "# # Set the batch size to 32 and use GPU acceleration\n",
    "# batch_size = 32\n",
    "# dataset = dataset.batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyModel(Model):\n",
    "#     def __init__(self, input_shape):\n",
    "#         super(MyModel, self).__init__()\n",
    "#         self.conv1 = Conv2D(32, 3, activation='relu', input_shape=input_shape)\n",
    "#         # self.conv1 = Conv2D(32, 3, activation='relu', )\n",
    "#         self.max1 = MaxPool2D((2, 2))\n",
    "#         self.conv2 = Conv2D(16, (3, 3), activation='relu')\n",
    "#         self.flatten = Flatten()\n",
    "#         self.d1 = Dense(128, activation='relu')\n",
    "#         self.d2 = Dense(1000)\n",
    "\n",
    "#     def call(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.max1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.flatten(x)\n",
    "#         x = self.d1(x)\n",
    "#         return self.d2(x)\n",
    "\n",
    "# # Create an instance of the model\n",
    "# model = MyModel((512, 512, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(64, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv1_1 = Conv2D(64, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        \n",
    "        self.conv2 = Conv2D(128, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv2_1 = Conv2D(128, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        \n",
    "        self.conv3 = Conv2D(256, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv3_1 = Conv2D(256, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv3_2 = Conv2D(256, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv3_3 = Conv2D(256, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        \n",
    "        self.conv4 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv4_1 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv4_2 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv4_3 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        \n",
    "        self.conv5 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv5_1 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv5_2 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        self.conv5_3 = Conv2D(512, kernel_size = (3, 3),  activation='relu', padding = 'same')\n",
    "        \n",
    "        self.pooling = MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same')\n",
    "        \n",
    "        self.drop = Dropout(rate = 0.2)\n",
    "        self.flatten = Flatten()\n",
    "#         self.dense1 = Dense(4096, activation='relu')\n",
    "#         self.dense2 = Dense(2048, activation='relu')\n",
    "        self.dense3 = Dense(1024, activation='relu')\n",
    "#         self.dense4 = Dense(512, activation='relu')\n",
    "        self.dense_output = Dense(120, activation = 'softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        \n",
    "        # Block 1\n",
    "        cnn1_1 = self.conv1(x)\n",
    "        cnn1_2 = self.conv1_1(cnn1_1)\n",
    "        pool = self.pooling(cnn1_2)\n",
    "\n",
    "        \n",
    "        #  Block 2\n",
    "        cnn2_1 = self.conv2(pool)\n",
    "        cnn2_2 = self.conv2_1(cnn2_1)\n",
    "        pool = self.pooling(cnn2_2)\n",
    "        \n",
    "        # Block 3\n",
    "        cnn3_1 = self.conv3(pool)\n",
    "        cnn3_2 = self.conv3_1(cnn3_1)\n",
    "        cnn3_3 = self.conv3_2(cnn3_2)\n",
    "        cnn3_4 = self.conv3_3(cnn3_3)\n",
    "        pool = self.pooling(cnn3_4)\n",
    "        \n",
    "        # Block 4\n",
    "        cnn4_1 = self.conv4(pool)\n",
    "        cnn4_2 = self.conv4_1(cnn4_1)\n",
    "        cnn4_3 = self.conv4_2(cnn4_2)\n",
    "        cnn4_4 = self.conv4_3(cnn4_3)\n",
    "        pool = self.pooling(cnn4_4)\n",
    "        \n",
    "        # Block 5\n",
    "        cnn5_1 = self.conv5(pool)\n",
    "        cnn5_2 = self.conv5_1(cnn5_1)\n",
    "        cnn5_3 = self.conv5_2(cnn5_2)\n",
    "        cnn5_4 = self.conv5_3(cnn5_3)\n",
    "        pool = self.pooling(cnn5_4)\n",
    "        \n",
    "        # Block 6   \n",
    "        flatten_1  = self.flatten(pool)\n",
    "#         hidden_1 = self.dense1(flatten_1)\n",
    "#         drop_1 = self.drop(hidden_1)\n",
    "#         hidden_2 = self.dense2(drop_1)\n",
    "#         drop_2 = self.drop(hidden_2)\n",
    "        hidden_3 = self.dense3(flatten_1)\n",
    "#         hidden_4 = self.dense4(hidden_3)\n",
    "        return self.dense_output(hidden_3)\n",
    "\n",
    "# Create an instance of the model\n",
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(images, training=True)\n",
    "    loss = loss_object(labels, predictions)\n",
    "  gradients = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def test_step(images, labels):\n",
    "  # training=False is only needed if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  predictions = model(images, training=False)\n",
    "  t_loss = loss_object(labels, predictions)\n",
    "\n",
    "  test_loss(t_loss)\n",
    "  test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:47:54.979479: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [16]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-04-03 14:47:54.979946: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int64 and shape [16]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "/home/abduraxim/Documents/tensorflow_imagenet/venv/lib/python3.10/site-packages/keras/backend.py:5612: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-04-03 14:47:58.097835: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2147483648 exceeds 10% of free system memory.\n",
      "2023-04-03 14:47:58.654308: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2147483648 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "batch = 32\n",
    "image = []\n",
    "label = []\n",
    "sanoq = 0\n",
    "for epoch in range(EPOCHS):\n",
    "  # Reset the metrics at the start of the next epoch\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  test_accuracy.reset_states()\n",
    "  for data in dataset:\n",
    "      images = data[\"image\"]\n",
    "      labels = data[\"label\"]\n",
    "      # print(images.shape)\n",
    "      # print(labels/255.0)\n",
    "      train_step(tf.cast(images, tf.float32) / 255.0, tf.cast(labels, tf.float32) / 255.0)\n",
    "\n",
    "\n",
    "  # for exampe in tfds.as_numpy(img['test']):\n",
    "  #     if sanoq !=32:\n",
    "  #       image.append(exampe['image']/255.0)\n",
    "  #       label.append(exampe['label']/255.0)\n",
    "  #       continue\n",
    "  #     sanoq = 0\n",
    "  #     image_np = np.array(image)\n",
    "  #     label_np = np.array(label)\n",
    "  #     train_step(image_np, label_np)\n",
    "  #     image.clear()\n",
    "  #     label.clear()\n",
    "\n",
    "\n",
    "#   for test_images, test_labels in test_ds:\n",
    "#     test_step(test_images, test_labels)\n",
    "\n",
    "  print(\n",
    "    f'Epoch {epoch + 1}, '\n",
    "    f'Loss: {train_loss.result()}, '\n",
    "    f'Accuracy: {train_accuracy.result() * 100}, '\n",
    "    f'Test Loss: {test_loss.result()}, '\n",
    "    f'Test Accuracy: {test_accuracy.result() * 100}'\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
